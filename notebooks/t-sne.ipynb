{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import pickle, random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "feature_folder = \"/home/neo/ml1/code/ML1_project/features/\"\n",
    "random.RandomState=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = '/home/neo/ml1/code/ML1_project/rbm_log_4096'\n",
    "metadata = os.path.join(LOG_DIR,'metadata.tsv')\n",
    "labels = pickle.load(open(feature_folder+\"labels.pkl\", \"rb\"))\n",
    "features = np.array(pickle.load(open(feature_folder+\"features_rbm_4096.pkl\", \"rb\")))\n",
    "words = pickle.load(open(feature_folder+\"final_words.pkl\",\"rb\"))\n",
    "features = [np.ndarray.tolist(element) for element in features] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features=[]\n",
    "new_labels=[]\n",
    "per_domain_samples = 10000//7\n",
    "new_features = random.sample(features[:15404],per_domain_samples)\n",
    "new_features += random.sample(features[15405:25836],per_domain_samples)\n",
    "new_features += random.sample(features[25837:28607],per_domain_samples)\n",
    "new_features += random.sample(features[28608:41803],per_domain_samples)\n",
    "new_features += random.sample(features[41804:61082],per_domain_samples)\n",
    "new_features += random.sample(features[61083:87000],per_domain_samples)\n",
    "new_features += random.sample(features[87001:168926],per_domain_samples)\n",
    "\n",
    "new_labels = random.sample(labels[:15404],per_domain_samples)\n",
    "new_labels += random.sample(labels[15405:25836],per_domain_samples)\n",
    "new_labels += random.sample(labels[25837:28607],per_domain_samples)\n",
    "new_labels += random.sample(labels[28608:41803],per_domain_samples)\n",
    "new_labels += random.sample(labels[41804:61082],per_domain_samples)\n",
    "new_labels += random.sample(labels[61083:87000],per_domain_samples)\n",
    "new_labels += random.sample(labels[87001:168926],per_domain_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0361582 , -0.03402048, -0.02112159, ..., -0.00178939,\n",
       "        0.02064374,  0.02015078])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(features[0])-np.array(features[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9996"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of labels:9996\n",
      "Length of features:9996\n",
      "Length of words:11764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of labels:{0}\\nLength of features:{1}\\nLength of words:{2}\\n\"\\\n",
    "      .format(len(new_labels),len(new_features),len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels = [label[0] for label in labels]\n",
    "new_labels2 = []\n",
    "for label in labels:\n",
    "    new_labels2.append(new_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split = min(labels.count(\"cooking\"),labels.count(\"robotics\"))\n",
    "# strat = [\"cooking\" for x in range(split//2)] + [\"robotics\" for x in range(split//2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stratSplit = StratifiedShuffleSplit(labels, 1, test_size=0.77,random_state=42)\n",
    "# StratifiedShuffleSplit(y, n_iter=1, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train, feature_test, label_train, label_test = train_test_split(new_features, new_labels, \\\n",
    "                                                    test_size=0.5, random_state=0)\n",
    "# word_train, word_test, label_train, label_test = train_test_split(words, new_labels, \\\n",
    "#                                                     test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mnist = input_data.read_data_sets('MNIST_data')\n",
    "X_init = tf.placeholder(tf.float32, shape=(len(feature_train), len(features[0])))\n",
    "images = tf.Variable(X_init)\n",
    "# images = tf.Variable(feature_train, name='features')\n",
    "# images = tf.Variable(X_test, name='images')\n",
    "# im_labels = []\n",
    "# for word in y_test:\n",
    "#     im_labels.append(labels[words.index(word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(metadata, 'w') as metadata_file:\n",
    "    for row in label_train:\n",
    "        metadata_file.write('%s\\n' % row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/neo/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver([images])\n",
    "\n",
    "    sess.run(tf.initialize_all_variables(), feed_dict={X_init: feature_train})\n",
    "    saver.save(sess, os.path.join(LOG_DIR, 'features.ckpt'))\n",
    "\n",
    "    config = projector.ProjectorConfig()\n",
    "    # One can add multiple embeddings.\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = images.name\n",
    "    # Link this tensor to its metadata file (e.g. labels).\n",
    "    embedding.metadata_path = metadata\n",
    "    # Saves a config file that TensorBoard will read during startup.\n",
    "    projector.visualize_embeddings(tf.summary.FileWriter(LOG_DIR), config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
