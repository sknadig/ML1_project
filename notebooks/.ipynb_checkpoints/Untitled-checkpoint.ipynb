{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "from data_reader import News20\n",
    "from rsm import RSM\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "import time\n",
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBasic untested version of Replicated Softmax:\\n@inproceedings{hinton2009replicated,\\n  title={Replicated softmax: an undirected topic model},\\n  author={Hinton, Geoffrey E and Salakhutdinov, Ruslan R},\\n  booktitle={Advances in neural information processing systems},\\n  pages={1607--1614},\\n  year={2009}\\n}\\nbased on Theano RBM implementation from deeplearning.net.\\nTo test download the matlab preprocessed dataset from http://qwone.com/~jason/20Newsgroups/\\nand put it in the appropriate folder (see below).\\nThis implementation is supposed to provide a framework for further work on RSM,\\nnot just the good results right away.\\n@author: Michal Lisicki\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Basic untested version of Replicated Softmax:\n",
    "@inproceedings{hinton2009replicated,\n",
    "  title={Replicated softmax: an undirected topic model},\n",
    "  author={Hinton, Geoffrey E and Salakhutdinov, Ruslan R},\n",
    "  booktitle={Advances in neural information processing systems},\n",
    "  pages={1607--1614},\n",
    "  year={2009}\n",
    "}\n",
    "based on Theano RBM implementation from deeplearning.net.\n",
    "To test download the matlab preprocessed dataset from http://qwone.com/~jason/20Newsgroups/\n",
    "and put it in the appropriate folder (see below).\n",
    "This implementation is supposed to provide a framework for further work on RSM,\n",
    "not just the good results right away.\n",
    "@author: Michal Lisicki\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compile_and_train_rsm(data_x,\n",
    "    learning_rate=0.1,\n",
    "    training_epochs=15,\n",
    "    batch_size=20,\n",
    "    n_chains=20, \n",
    "    n_hidden=20):\n",
    "\n",
    "    train_set_x = theano.shared(numpy.asarray(data_x, dtype=theano.config.floatX), borrow=True)\n",
    "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "    if((float(train_set_x.get_value(borrow=True).shape[0]) / batch_size)!=float(n_train_batches)):\n",
    "        n_train_batches+=1\n",
    "\n",
    "    index = T.lscalar()\n",
    "    x = T.matrix('x')\n",
    "\n",
    "    rng = numpy.random.RandomState(123)\n",
    "    theano_rng = RandomStreams(rng.randint(2 ** 30))\n",
    "\n",
    "    persistent_chain = theano.shared(numpy.zeros((batch_size, n_hidden), dtype=theano.config.floatX), borrow=True)\n",
    "\n",
    "    rsm = RSM(input=x, n_visible=train_set_x.get_value(borrow=True).shape[1],\n",
    "              n_hidden=n_hidden, numpy_rng=rng, theano_rng=theano_rng)\n",
    "\n",
    "    cost, updates = rsm.get_cost_updates(lr=learning_rate, persistent=None, k=1)\n",
    "\n",
    "    train_rsm = theano.function(\n",
    "        [index],\n",
    "        cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_set_x[index * batch_size: (index + 1) * batch_size]\n",
    "        },\n",
    "        name='train_rbm'\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in xrange(training_epochs):\n",
    "        mean_cost = []\n",
    "        for batch_index in xrange(n_train_batches):\n",
    "            mean_cost += [train_rsm(batch_index)]\n",
    "\n",
    "        print('Training epoch %d, cost is ' % epoch, numpy.mean(mean_cost))\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    pretraining_time = (end_time - start_time)\n",
    "\n",
    "    print ('Training took %f seconds' % (pretraining_time))\n",
    "    return rsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ab8570f16506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# download dataset from http://qwone.com/~jason/20Newsgroups/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNews20\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/neo/ml1/code/temp/ReplicatedSoftmax/20news-bydate/matlab'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwhich_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetDocumentWordFrequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# limit number of documents and features for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrbm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile_and_train_rsm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/neo/ml1/code/ML1_project/notebooks/data_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, vector_size, which_set, excluded_words, most_common_idx)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mfull_frequencies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mfull_frequencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# extract the indicies of [vector_size] most common words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# download dataset from http://qwone.com/~jason/20Newsgroups/\n",
    "train_dataset=News20(path='/home/neo/ml1/code/temp/ReplicatedSoftmax/20news-bydate/matlab',which_set=\"train\",vector_size=200)\n",
    "x,y = train_dataset.getDocumentWordFrequencies()\n",
    "x=x[:1000,:200] # limit number of documents and features for testing\n",
    "rbm=compile_and_train_rsm(x)\n",
    "\n",
    "#example of accessing the data\n",
    "print(rbm.params[0].get_value()) # weights\n",
    "print(rbm.params[1].get_value()) # hidden biases\n",
    "print(rbm.params[2].get_value()) # visible biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
